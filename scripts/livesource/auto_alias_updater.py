# auto_alias_updater.py
"""
è‡ªåŠ¨åŒ–é¢‘é“åˆ«åæ›´æ–°ç³»ç»Ÿ
æ”¯æŒä»è®¢é˜…æºæ–‡ä»¶è¯»å–URLåˆ—è¡¨ï¼Œè‡ªåŠ¨æ‹‰å–ç›´æ’­æºå¹¶ç”Ÿæˆé¢‘é“åˆ«åçº æ­£æ–‡ä»¶
è¾“å‡ºè·¯å¾„: scripts/livesource/corrections_name.txt
"""

import requests
import re
import os
import time
import sys
from collections import defaultdict
from typing import Dict, List, Set, Tuple
import hashlib

# é»˜è®¤è®¢é˜…æºURLåˆ—è¡¨ï¼ˆå¦‚æœè®¢é˜…æºæ–‡ä»¶ä¸å­˜åœ¨æ—¶ä½¿ç”¨ï¼‰
DEFAULT_SUBSCRIPTION_URLS = [
    "https://raw.githubusercontent.com/xiaoran67/update/refs/heads/main/output/Collection/LiveSource2025.txt",
    "https://raw.githubusercontent.com/xiaoran67/update/refs/heads/main/output/Collection/LiveSource2026.txt",
    "https://raw.githubusercontent.com/develop202/migu_video/refs/heads/main/interface.txt",
    "https://raw.githubusercontent.com/kakaxi-1/IPTV/refs/heads/main/iptv.txt",
    "https://freetv.fun/test_channels_original_new.txt",
]

# é»˜è®¤è®¢é˜…æºæ–‡ä»¶å
SUBSCRIPTION_FILE = "subscription_sources.txt"
# è¾“å‡ºæ–‡ä»¶è·¯å¾„
OUTPUT_FILE = "scripts/livesource/corrections_name.txt"

class LiveSourceFetcher:
    """ç›´æ’­æºæ‹‰å–å™¨"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.timeout = 30
        self.max_retries = 2
    
    def fetch_live_sources(self, source_urls: List[str]) -> Dict[str, str]:
        """ä»å¤šä¸ªURLæ‹‰å–ç›´æ’­æºå†…å®¹"""
        all_content = {}
        
        for url in source_urls:
            for attempt in range(self.max_retries):
                try:
                    print(f"ğŸ“¡ æ­£åœ¨æ‹‰å– ({attempt+1}/{self.max_retries}): {url}")
                    response = self.session.get(url, timeout=self.timeout)
                    response.encoding = 'utf-8'
                    
                    if response.status_code == 200:
                        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
                        all_content[f"source_{url_hash}"] = response.text
                        print(f"âœ… æˆåŠŸæ‹‰å–: {url}")
                        break
                    else:
                        print(f"âŒ æ‹‰å–å¤±è´¥ {url}: HTTP {response.status_code}")
                        
                except Exception as e:
                    print(f"âš ï¸ æ‹‰å–é”™è¯¯ {url}: {e}")
                    if attempt == self.max_retries - 1:
                        print(f"âŒ æ”¾å¼ƒæ‹‰å–: {url}")
                
                time.sleep(1)
        
        return all_content

class AdvancedChannelParser:
    """é«˜çº§é¢‘é“è§£æå™¨"""
    
    def __init__(self):
        self.clean_patterns = [
            r'\[.*?\]', r'\(.*?\)', r'ã€.*?ã€‘', r'#EXTINF.*?,',
            r'group-title=".*?"', r'tvg-name=".*?"', r'tvg-id=".*?"',
            r'tvg-logo=".*?"'
        ]
        
        self.quality_indicators = [
            '4K', '1080P', '720P', 'HD', 'è¶…æ¸…', 'é«˜æ¸…', 'æ ‡æ¸…', 'è“å…‰', 'FHD'
        ]

    def parse_channels_from_content(self, content: str) -> List[str]:
        """ä»å†…å®¹ä¸­è§£æå‡ºé¢‘é“åç§°åˆ—è¡¨"""
        channels = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            channel_name = self.extract_channel_name(line)
            if channel_name and len(channel_name) > 1:
                channels.append(channel_name)
        
        return list(set(channels))

    def extract_channel_name(self, line: str) -> str:
        """ä»å•è¡Œå†…å®¹æå–é¢‘é“åç§°"""
        # M3Uæ ¼å¼: #EXTINF:-1,é¢‘é“åç§°
        if line.startswith('#EXTINF'):
            match = re.search(r'#EXTINF:.*?,(.+)', line)
            if match:
                return self.clean_channel_name(match.group(1))
        
        # TXTæ ¼å¼: é¢‘é“åç§°,URL
        if ',' in line and ('http://' in line or 'https://' in line):
            parts = line.split(',', 1)
            if len(parts) >= 2:
                return self.clean_channel_name(parts[0])
        
        return self.clean_channel_name(line)

    def clean_channel_name(self, name: str) -> str:
        """æ¸…æ´—é¢‘é“åç§°"""
        if not name:
            return ""
        
        cleaned = name
        for pattern in self.clean_patterns:
            cleaned = re.sub(pattern, '', cleaned)
        
        cleaned = re.sub(r'https?://[^\s]+', '', cleaned)
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        cleaned = re.sub(r'^[,\s]+|[,\s]+$', '', cleaned)
        
        return cleaned

class ChannelAliasManager:
    """é¢‘é“åˆ«åç®¡ç†å™¨"""
    
    def __init__(self):
        self.standard_to_aliases: Dict[str, Set[str]] = defaultdict(set)
        self.alias_to_standard: Dict[str, str] = {}

    def find_standard_name(self, channel_name: str) -> Tuple[str, bool]:
        """æŸ¥æ‰¾é¢‘é“å¯¹åº”çš„æ ‡å‡†åç§°"""
        if channel_name in self.alias_to_standard:
            return self.alias_to_standard[channel_name], False
        
        clean_name = self.clean_for_matching(channel_name)
        for alias, standard in self.alias_to_standard.items():
            if self.clean_for_matching(alias) == clean_name:
                return standard, False
        
        standard_name = self.generate_standard_name(channel_name)
        return standard_name, True

    def clean_for_matching(self, name: str) -> str:
        """ä¸ºåŒ¹é…æ¸…ç†åç§°"""
        name = name.lower()
        for quality in ['4k', '1080p', '720p', 'hd', 'è¶…æ¸…', 'é«˜æ¸…', 'æ ‡æ¸…']:
            name = name.replace(quality, '')
        name = re.sub(r'[^\w]', '', name)
        return name

    def generate_standard_name(self, channel_name: str) -> str:
        """ç”Ÿæˆæ ‡å‡†é¢‘é“åç§°"""
        # CCTVé¢‘é“
        cctv_match = re.search(r'CCTV[\-\s]*(\d+\+?)', channel_name, re.IGNORECASE)
        if cctv_match:
            num = cctv_match.group(1)
            return f"CCTV{num.upper()}"
        
        # å«è§†é¢‘é“
        for region in ['æ¹–å—', 'æ±Ÿè‹', 'æµ™æ±Ÿ', 'åŒ—äº¬', 'ä¸œæ–¹', 'å¹¿ä¸œ', 'æ·±åœ³', 'å¤©æ´¥']:
            if region in channel_name and 'å«è§†' in channel_name:
                return f"{region}å«è§†"
        
        # å…¶ä»–é¢‘é“
        clean_name = self.clean_channel_name(channel_name)
        return clean_name[:30] if clean_name else "Unknown"

    def clean_channel_name(self, name: str) -> str:
        """åŸºç¡€é¢‘é“åç§°æ¸…æ´—"""
        for quality in ['4K', '1080P', '720P', 'HD', 'è¶…æ¸…', 'é«˜æ¸…', 'æ ‡æ¸…']:
            name = name.replace(quality, '')
        name = re.sub(r'\s+', ' ', name).strip()
        return name

    def add_channel(self, channel_name: str):
        """æ·»åŠ é¢‘é“åˆ°åˆ«åç³»ç»Ÿ"""
        if not channel_name or len(channel_name) < 2:
            return
            
        standard_name, is_new = self.find_standard_name(channel_name)
        
        if is_new:
            print(f"ğŸ†• å‘ç°æ–°é¢‘é“: {channel_name} -> {standard_name}")
            base_aliases = self.generate_base_aliases(standard_name)
            self.standard_to_aliases[standard_name].update(base_aliases)
            
            for alias in base_aliases:
                self.alias_to_standard[alias] = standard_name
        
        if channel_name != standard_name:
            self.standard_to_aliases[standard_name].add(channel_name)
            self.alias_to_standard[channel_name] = standard_name

    def generate_base_aliases(self, standard_name: str) -> List[str]:
        """ä¸ºåŸºç¡€é¢‘é“åç§°ç”ŸæˆåŸºç¡€åˆ«å"""
        aliases = []
        
        if standard_name.startswith('CCTV'):
            num = standard_name[4:]
            aliases.extend([
                f"CCTV-{num}", f"CCTV {num}", f"CCTV{num.zfill(2)}",
                standard_name.lower(), f"cctv-{num.lower()}", f"cctv {num.lower()}"
            ])
            
            cctv_types = {
                '1': ['ç»¼åˆ'], '2': ['è´¢ç»'], '3': ['ç»¼è‰º'], 
                '4': ['å›½é™…', 'ä¸­æ–‡å›½é™…'], '5': ['ä½“è‚²'], '5+': ['ä½“è‚²', 'ä½“è‚²èµ›äº‹'],
                '6': ['ç”µå½±'], '7': ['å›½é˜²å†›äº‹', 'å†›å†œ'], '8': ['ç”µè§†å‰§'],
                '9': ['çºªå½•', 'çºªå½•ç‰‡'], '10': ['ç§‘æ•™'], '11': ['æˆæ›²']
            }
            
            if num in cctv_types:
                for ctype in cctv_types[num]:
                    aliases.extend([
                        f"{standard_name}{ctype}", f"CCTV-{num}{ctype}", f"CCTV {num} {ctype}"
                    ])
        
        elif standard_name.endswith('å«è§†'):
            base = standard_name[:-2]
            aliases.extend([f"{base}ç”µè§†å°", f"{base}å°", standard_name.lower()])
        
        return aliases

    def save_aliases_to_file(self, output_path: str):
        """ä¿å­˜åˆ«ååˆ°æŒ‡å®šæ–‡ä»¶"""
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        cctv_channels = {}
        satellite_channels = {}
        other_channels = {}
        
        for standard, aliases in self.standard_to_aliases.items():
            unique_aliases = sorted([a for a in set(aliases) if a and a != standard])
            
            if standard.startswith('CCTV'):
                cctv_channels[standard] = unique_aliases
            elif 'å«è§†' in standard:
                satellite_channels[standard] = unique_aliases
            else:
                other_channels[standard] = unique_aliases
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# è¿™æ˜¯é¢‘é“åç§°çš„åˆ«ååå•ï¼Œç”¨äºè·å–æ¥å£æ—¶å°†å¤šç§åç§°æ˜ å°„ä¸ºä¸€ä¸ªåç§°çš„ç»“æœï¼Œå¯ä»¥æå‡è·å–é‡ä¸å‡†ç¡®ç‡\n")
            f.write("# æ ¼å¼ï¼šæ¨¡æ¿é¢‘é“åç§°,åˆ«å1,åˆ«å2,åˆ«å3\n")
            f.write("# This is the alias list for channel names, used to map multiple names to a single name when fetching from the interface, improving the fetch volume and accuracy.\n")
            f.write("# Format: TemplateChannelName,Alias1,Alias2,Alias3\n\n")
            
            if cctv_channels:
                f.write("# å¤®è§†é¢‘é“\n")
                for standard in sorted(cctv_channels.keys()):
                    aliases_str = ','.join(cctv_channels[standard])
                    f.write(f"{standard},{aliases_str}\n")
                f.write("\n")
            
            if satellite_channels:
                f.write("# å«è§†é¢‘é“\n")
                for standard in sorted(satellite_channels.keys()):
                    aliases_str = ','.join(satellite_channels[standard])
                    f.write(f"{standard},{aliases_str}\n")
                f.write("\n")
            
            if other_channels:
                f.write("# å…¶ä»–é¢‘é“\n")
                for standard in sorted(other_channels.keys()):
                    aliases_str = ','.join(other_channels[standard])
                    f.write(f"{standard},{aliases_str}\n")
        
        print(f"ğŸ’¾ åˆ«åæ–‡ä»¶å·²ä¿å­˜: {output_path}")

class AutoAliasUpdater:
    """è‡ªåŠ¨åˆ«åæ›´æ–°å™¨"""
    
    def __init__(self):
        self.fetcher = LiveSourceFetcher()
        self.parser = AdvancedChannelParser()
        self.manager = ChannelAliasManager()

    def load_subscription_sources(self, subscription_file: str) -> List[str]:
        """ä»è®¢é˜…æºæ–‡ä»¶åŠ è½½URLåˆ—è¡¨"""
        urls = []
        
        try:
            if os.path.exists(subscription_file):
                print(f"ğŸ“‹ ä»æ–‡ä»¶åŠ è½½è®¢é˜…æº: {subscription_file}")
                with open(subscription_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#') and (
                            line.startswith('http://') or line.startswith('https://')
                        ):
                            urls.append(line)
            else:
                print(f"ğŸ“‹ è®¢é˜…æºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤è®¢é˜…æº")
                urls = DEFAULT_SUBSCRIPTION_URLS
            
            print(f"ğŸ“‹ åŠ è½½äº† {len(urls)} ä¸ªè®¢é˜…æº")
            return urls
            
        except Exception as e:
            print(f"âŒ åŠ è½½è®¢é˜…æºæ–‡ä»¶å¤±è´¥: {e}")
            print(f"ğŸ“‹ ä½¿ç”¨é»˜è®¤è®¢é˜…æº")
            return DEFAULT_SUBSCRIPTION_URLS

    def update_aliases(self, subscription_file: str, output_file: str) -> bool:
        """æ›´æ–°é¢‘é“åˆ«åç³»ç»Ÿ"""
        print("ğŸš€ å¼€å§‹æ›´æ–°é¢‘é“åˆ«åç³»ç»Ÿ...")
        
        source_urls = self.load_subscription_sources(subscription_file)
        if not source_urls:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è®¢é˜…æºURL")
            return False

        contents = self.fetcher.fetch_live_sources(source_urls)
        if not contents:
            print("âŒ æœªèƒ½æˆåŠŸæ‹‰å–ä»»ä½•ç›´æ’­æºå†…å®¹")
            return False

        total_channels = 0
        successful_sources = 0
        
        for source_name, content in contents.items():
            if content.strip():
                successful_sources += 1
                channels = self.parser.parse_channels_from_content(content)
                print(f"ğŸ“º {source_name}: è§£æåˆ° {len(channels)} ä¸ªé¢‘é“")
                total_channels += len(channels)
                
                for channel in channels:
                    self.manager.add_channel(channel)

        current_count = len(self.manager.standard_to_aliases)
        
        print(f"\nğŸ“Š === æ›´æ–°ç»Ÿè®¡ ===")
        print(f"âœ… æˆåŠŸæ‹‰å–æº: {successful_sources}/{len(source_urls)}")
        print(f"ğŸ“º å¤„ç†é¢‘é“æ€»æ•°: {total_channels}")
        print(f"ğŸ·ï¸ æ ‡å‡†é¢‘é“æ•°é‡: {current_count}")
        
        if current_count > 0:
            self.manager.save_aliases_to_file(output_file)
            return True
        else:
            print("âŒ æœªèƒ½ç”Ÿæˆä»»ä½•é¢‘é“åˆ«å")
            return False

def main():
    """ä¸»å‡½æ•°"""
    updater = AutoAliasUpdater()
    success = updater.update_aliases(SUBSCRIPTION_FILE, OUTPUT_FILE)
    
    # è®¾ç½®é€€å‡ºä»£ç 
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()